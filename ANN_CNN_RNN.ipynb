{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN - CNN - RNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LInu08RexdpI",
        "colab_type": "code",
        "outputId": "b3258205-1139-4b64-d1ae-7dc96fdb8188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!pip install theano\n",
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano) (1.17.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hI0Ro46xeGw",
        "colab_type": "code",
        "outputId": "766845b7-d116-4c34-c031-e662bcee6c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PnofbtHxeNR",
        "colab_type": "code",
        "outputId": "db664c63-d8c5-4fba-edd0-f5849efe7a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-1.15.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPHPI8QlxeQf",
        "colab_type": "code",
        "outputId": "44b2aa80-d1d6-4185-f6b2-e836fa9d784d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 116kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 27.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.1)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.8.0)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pgbnYJa0NEu",
        "colab_type": "text"
      },
      "source": [
        "ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLaNmOLa1wye",
        "colab_type": "code",
        "outputId": "b30a1024-2784-4e9f-ac74-58a41861ef03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import theano\n",
        "import tensorflow\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETPFZb0g99JD",
        "colab_type": "code",
        "outputId": "14cb4350-42c0-4743-a495-b31d2f1b2f94",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-97c5659a-5a58-4aee-825a-8ec480998db5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-97c5659a-5a58-4aee-825a-8ec480998db5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Churn_Modelling.csv to Churn_Modelling.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0t0cavo_Qi7",
        "colab_type": "code",
        "outputId": "fd4865ae-6f34-420e-9b17-56e99d813794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['Churn_Modelling.csv']))\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3psZzLzAAief",
        "colab_type": "code",
        "outputId": "c9b3f422-baf1-43e1-ae9f-75f33c7bad87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0INdnj3QB0ce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:, 3:13].values\n",
        "y = df.iloc[:, 13].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9xbbkp6VJ5m",
        "colab_type": "code",
        "outputId": "0b2feb99-52f0-499a-9899-96ebd562bea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
              "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
              "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
              "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
              "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUsIWc0oVcyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_geo = LabelEncoder()\n",
        "X[:, 1] = le_geo.fit_transform(X[:, 1])\n",
        "\n",
        "le_gender = LabelEncoder()\n",
        "X[:, 2] = le_gender.fit_transform(X[:,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhwmvR3uWcJ1",
        "colab_type": "code",
        "outputId": "f5d5bfdc-be7e-4adc-ed85-dc1bcaa5fbdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
              "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
              "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
              "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
              "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SketqBE6WoEl",
        "colab_type": "code",
        "outputId": "5e9d8730-3529-4cd8-d5b5-620f524c4956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(categorical_features = [1])\n",
        "X = ohe.fit_transform(X).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmZ40PykWoHy",
        "colab_type": "code",
        "outputId": "51102e6e-97ef-4a88-a3f6-22ccf082c1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
              "        1.0000000e+00, 1.0134888e+05],\n",
              "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,\n",
              "        1.0000000e+00, 1.1254258e+05],\n",
              "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
              "        0.0000000e+00, 1.1393157e+05],\n",
              "       ...,\n",
              "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
              "        1.0000000e+00, 4.2085580e+04],\n",
              "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
              "        0.0000000e+00, 9.2888520e+04],\n",
              "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n",
              "        0.0000000e+00, 3.8190780e+04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15Hf-UYdXqf2",
        "colab_type": "code",
        "outputId": "b60848a9-45ea-473f-d5e2-e41588763cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "X = X[:, 1:] # Dummy variable trap prevention\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0000000e+00, 0.0000000e+00, 6.1900000e+02, ..., 1.0000000e+00,\n",
              "        1.0000000e+00, 1.0134888e+05],\n",
              "       [0.0000000e+00, 1.0000000e+00, 6.0800000e+02, ..., 0.0000000e+00,\n",
              "        1.0000000e+00, 1.1254258e+05],\n",
              "       [0.0000000e+00, 0.0000000e+00, 5.0200000e+02, ..., 1.0000000e+00,\n",
              "        0.0000000e+00, 1.1393157e+05],\n",
              "       ...,\n",
              "       [0.0000000e+00, 0.0000000e+00, 7.0900000e+02, ..., 0.0000000e+00,\n",
              "        1.0000000e+00, 4.2085580e+04],\n",
              "       [1.0000000e+00, 0.0000000e+00, 7.7200000e+02, ..., 1.0000000e+00,\n",
              "        0.0000000e+00, 9.2888520e+04],\n",
              "       [0.0000000e+00, 0.0000000e+00, 7.9200000e+02, ..., 1.0000000e+00,\n",
              "        0.0000000e+00, 3.8190780e+04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aivbxwwTB_zT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpDGDjEtB_wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split as tts\n",
        "X_train, X_test, y_train, y_test = tts(X, y, random_state = 42, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "350oOJtU03M5",
        "colab_type": "text"
      },
      "source": [
        "Building the ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RxnhHWpB_8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "classifier = Sequential() #Initialise the model\n",
        "\n",
        "classifier.add(Dense(units = 6, activation = 'relu', kernel_initializer='uniform', input_shape = (11, )))\n",
        "classifier.add(Dense(units = 12, activation = \"relu\", kernel_initializer=\"uniform\"))\n",
        "classifier.add(Dense(units = 1, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy', 'mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UheNcS7m3WDs",
        "colab_type": "code",
        "outputId": "0a6dd483-d231-49f9-93d8-3e39abda8490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 8000 samples\n",
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 1s 146us/sample - loss: 0.4866 - accuracy: 0.7940 - mse: 0.1593\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 1s 118us/sample - loss: 0.4312 - accuracy: 0.7945 - mse: 0.1371\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 1s 116us/sample - loss: 0.4242 - accuracy: 0.8036 - mse: 0.1337\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 1s 124us/sample - loss: 0.4200 - accuracy: 0.8254 - mse: 0.1317\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 1s 125us/sample - loss: 0.4178 - accuracy: 0.8294 - mse: 0.1305\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 1s 136us/sample - loss: 0.4162 - accuracy: 0.8315 - mse: 0.1297\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 1s 125us/sample - loss: 0.4143 - accuracy: 0.8322 - mse: 0.1290\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 1s 135us/sample - loss: 0.4133 - accuracy: 0.8339 - mse: 0.1283\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 1s 134us/sample - loss: 0.4121 - accuracy: 0.8336 - mse: 0.1281\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 1s 136us/sample - loss: 0.4112 - accuracy: 0.8339 - mse: 0.1274\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 1s 119us/sample - loss: 0.4105 - accuracy: 0.8344 - mse: 0.1273\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 1s 126us/sample - loss: 0.4096 - accuracy: 0.8336 - mse: 0.1267\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 1s 129us/sample - loss: 0.4091 - accuracy: 0.8349 - mse: 0.1266\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 1s 121us/sample - loss: 0.4090 - accuracy: 0.8339 - mse: 0.1264\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 1s 127us/sample - loss: 0.4084 - accuracy: 0.8340 - mse: 0.1262\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 1s 128us/sample - loss: 0.4082 - accuracy: 0.8347 - mse: 0.1261\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 1s 135us/sample - loss: 0.4074 - accuracy: 0.8340 - mse: 0.1259\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 1s 140us/sample - loss: 0.4076 - accuracy: 0.8350 - mse: 0.1257\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 1s 138us/sample - loss: 0.4073 - accuracy: 0.8347 - mse: 0.1256\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 1s 139us/sample - loss: 0.4067 - accuracy: 0.8341 - mse: 0.1254\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 1s 135us/sample - loss: 0.4066 - accuracy: 0.8355 - mse: 0.1255\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.4064 - accuracy: 0.8351 - mse: 0.1253\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.4060 - accuracy: 0.8344 - mse: 0.1252\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 1s 137us/sample - loss: 0.4059 - accuracy: 0.8345 - mse: 0.1250\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 1s 138us/sample - loss: 0.4059 - accuracy: 0.8357 - mse: 0.1254\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 1s 138us/sample - loss: 0.4056 - accuracy: 0.8344 - mse: 0.1251\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 1s 132us/sample - loss: 0.4056 - accuracy: 0.8361 - mse: 0.1249\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 1s 138us/sample - loss: 0.4056 - accuracy: 0.8350 - mse: 0.1251\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 1s 138us/sample - loss: 0.4050 - accuracy: 0.8357 - mse: 0.1249\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 1s 133us/sample - loss: 0.4046 - accuracy: 0.8360 - mse: 0.1248\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 1s 126us/sample - loss: 0.4047 - accuracy: 0.8342 - mse: 0.1248\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 1s 125us/sample - loss: 0.4044 - accuracy: 0.8363 - mse: 0.1245\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 1s 129us/sample - loss: 0.4038 - accuracy: 0.8359 - mse: 0.1243\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 1s 125us/sample - loss: 0.4039 - accuracy: 0.8357 - mse: 0.1245\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 1s 134us/sample - loss: 0.4030 - accuracy: 0.8351 - mse: 0.1241\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 1s 133us/sample - loss: 0.4029 - accuracy: 0.8340 - mse: 0.1242\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 1s 130us/sample - loss: 0.4028 - accuracy: 0.8345 - mse: 0.1240\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 1s 135us/sample - loss: 0.4016 - accuracy: 0.8354 - mse: 0.1237\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 1s 139us/sample - loss: 0.4019 - accuracy: 0.8359 - mse: 0.1238\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 1s 143us/sample - loss: 0.4010 - accuracy: 0.8367 - mse: 0.1234\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 1s 137us/sample - loss: 0.4005 - accuracy: 0.8372 - mse: 0.1234\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 1s 138us/sample - loss: 0.4003 - accuracy: 0.8379 - mse: 0.1232\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 1s 137us/sample - loss: 0.3998 - accuracy: 0.8370 - mse: 0.1232\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 1s 132us/sample - loss: 0.3994 - accuracy: 0.8371 - mse: 0.1230\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 1s 143us/sample - loss: 0.3994 - accuracy: 0.8381 - mse: 0.1231\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 1s 126us/sample - loss: 0.3979 - accuracy: 0.8378 - mse: 0.1227\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 1s 123us/sample - loss: 0.3972 - accuracy: 0.8369 - mse: 0.1224\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 1s 126us/sample - loss: 0.3974 - accuracy: 0.8369 - mse: 0.1225\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 1s 120us/sample - loss: 0.3974 - accuracy: 0.8375 - mse: 0.1225\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 1s 124us/sample - loss: 0.3974 - accuracy: 0.8388 - mse: 0.1225\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 1s 121us/sample - loss: 0.3969 - accuracy: 0.8384 - mse: 0.1223\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 1s 131us/sample - loss: 0.3964 - accuracy: 0.8385 - mse: 0.1221\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 1s 136us/sample - loss: 0.3961 - accuracy: 0.8386 - mse: 0.1221\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 1s 141us/sample - loss: 0.3966 - accuracy: 0.8394 - mse: 0.1223\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 1s 139us/sample - loss: 0.3960 - accuracy: 0.8384 - mse: 0.1221\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 1s 137us/sample - loss: 0.3955 - accuracy: 0.8384 - mse: 0.1221\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 1s 135us/sample - loss: 0.3954 - accuracy: 0.8384 - mse: 0.1221\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3944 - accuracy: 0.8400 - mse: 0.1216\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 1s 120us/sample - loss: 0.3953 - accuracy: 0.8374 - mse: 0.1220\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 1s 126us/sample - loss: 0.3948 - accuracy: 0.8374 - mse: 0.1220\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 1s 124us/sample - loss: 0.3943 - accuracy: 0.8390 - mse: 0.1216\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 1s 140us/sample - loss: 0.3944 - accuracy: 0.8371 - mse: 0.1219\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 1s 125us/sample - loss: 0.3941 - accuracy: 0.8394 - mse: 0.1218\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 1s 119us/sample - loss: 0.3933 - accuracy: 0.8376 - mse: 0.1215\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 1s 124us/sample - loss: 0.3944 - accuracy: 0.8399 - mse: 0.1217\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3942 - accuracy: 0.8399 - mse: 0.1218\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 1s 125us/sample - loss: 0.3932 - accuracy: 0.8391 - mse: 0.1214\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 1s 138us/sample - loss: 0.3938 - accuracy: 0.8380 - mse: 0.1218\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 1s 135us/sample - loss: 0.3937 - accuracy: 0.8378 - mse: 0.1218\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 1s 121us/sample - loss: 0.3931 - accuracy: 0.8384 - mse: 0.1215\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 1s 125us/sample - loss: 0.3931 - accuracy: 0.8388 - mse: 0.1217\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 1s 133us/sample - loss: 0.3934 - accuracy: 0.8394 - mse: 0.1216\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 1s 128us/sample - loss: 0.3927 - accuracy: 0.8388 - mse: 0.1212\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 1s 124us/sample - loss: 0.3924 - accuracy: 0.8384 - mse: 0.1213\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 1s 119us/sample - loss: 0.3928 - accuracy: 0.8380 - mse: 0.1215\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3928 - accuracy: 0.8384 - mse: 0.1215\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 1s 119us/sample - loss: 0.3927 - accuracy: 0.8396 - mse: 0.1215\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3924 - accuracy: 0.8385 - mse: 0.1214\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3919 - accuracy: 0.8372 - mse: 0.1212\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3924 - accuracy: 0.8397 - mse: 0.1213\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3921 - accuracy: 0.8381 - mse: 0.1214\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 1s 119us/sample - loss: 0.3920 - accuracy: 0.8384 - mse: 0.1213\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 1s 121us/sample - loss: 0.3925 - accuracy: 0.8375 - mse: 0.1215\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 1s 123us/sample - loss: 0.3916 - accuracy: 0.8384 - mse: 0.1213\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 1s 120us/sample - loss: 0.3924 - accuracy: 0.8375 - mse: 0.1215\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 1s 120us/sample - loss: 0.3915 - accuracy: 0.8372 - mse: 0.1213\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 1s 138us/sample - loss: 0.3921 - accuracy: 0.8384 - mse: 0.1216\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 1s 125us/sample - loss: 0.3919 - accuracy: 0.8394 - mse: 0.1215\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 1s 118us/sample - loss: 0.3918 - accuracy: 0.8397 - mse: 0.1212\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 1s 124us/sample - loss: 0.3914 - accuracy: 0.8389 - mse: 0.1212\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3917 - accuracy: 0.8410 - mse: 0.1212\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 1s 125us/sample - loss: 0.3915 - accuracy: 0.8393 - mse: 0.1212\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 1s 124us/sample - loss: 0.3912 - accuracy: 0.8381 - mse: 0.1210\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3913 - accuracy: 0.8399 - mse: 0.1211\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3916 - accuracy: 0.8405 - mse: 0.1212\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 1s 123us/sample - loss: 0.3922 - accuracy: 0.8395 - mse: 0.1214\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 1s 121us/sample - loss: 0.3912 - accuracy: 0.8399 - mse: 0.1211\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 1s 127us/sample - loss: 0.3918 - accuracy: 0.8385 - mse: 0.1213\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 1s 122us/sample - loss: 0.3918 - accuracy: 0.8388 - mse: 0.1214\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 1s 123us/sample - loss: 0.3917 - accuracy: 0.8396 - mse: 0.1213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c19547320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_AhK58W4BpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred>0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBr3uzQn47-k",
        "colab_type": "code",
        "outputId": "0d1d856c-9fb2-4aca-aea2-0bee6d3536ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y76_test, y_pred)\n",
        "cm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1522,   85],\n",
              "       [ 239,  154]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdDAE9hD5gJK",
        "colab_type": "code",
        "outputId": "c102e628-9ffd-45f3-a1d7-548a19edec6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy = (1522+154)/2000\n",
        "accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.838"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ianXW4LS1Fm8",
        "colab_type": "text"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sC3uj1LBvea",
        "colab_type": "code",
        "outputId": "fe116fcf-d33a-4963-8e74-120f1052e336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "# Upgrading tensorflow\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.0.0-beta1\n",
        "\n",
        "import tensorflow\n",
        "import theano\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpV6sxCL1KRl",
        "colab_type": "text"
      },
      "source": [
        "Building CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlQUHWIjDiVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Convolution2D(32,3,3, input_shape = (64, 64, 3), activation='relu')) #using tensorflow, we input the shape of the image first and then the colour layers, viceversa for theano\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Convolution2D(64,3,3, activation='relu')) #using tensorflow, we input the shape of the image first and then the colour layers, viceversa for theano\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(units=128, activation = 'relu', kernel_initializer='uniform'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid', kernel_initializer='uniform'))\n",
        "\n",
        "classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy', 'mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnA0mFaHP_gj",
        "colab_type": "code",
        "outputId": "32229d04-6ed2-44e0-974f-1f46ebb9d10d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "\n",
        "img_width, img_height = 64, 64\n",
        "train_data_dir = '/gdrive/My Drive/Colab Notebooks/dataset/training_set'\n",
        "validation_data_dir = '/gdrive/My Drive/Colab Notebooks/dataset/test_set'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idlvmC5zBvki",
        "colab_type": "code",
        "outputId": "f310a7bc-f96b-442d-b256-921207cda8ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "classifier.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=8000, # Number of images in train set\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=2000) # Number of images in test set"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8006 images belonging to 2 classes.\n",
            "Found 2001 images belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "8000/8000 [==============================] - 5315s 664ms/step - loss: 0.5993 - accuracy: 0.6680 - mse: 0.2070 - val_loss: 0.5808 - val_accuracy: 0.6950 - val_mse: 0.1971\n",
            "Epoch 2/5\n",
            "8000/8000 [==============================] - 1689s 211ms/step - loss: 0.5178 - accuracy: 0.7415 - mse: 0.1728 - val_loss: 0.5773 - val_accuracy: 0.7092 - val_mse: 0.1951\n",
            "Epoch 3/5\n",
            "8000/8000 [==============================] - 1673s 209ms/step - loss: 0.4778 - accuracy: 0.7674 - mse: 0.1575 - val_loss: 0.5871 - val_accuracy: 0.7086 - val_mse: 0.1945\n",
            "Epoch 4/5\n",
            "8000/8000 [==============================] - 1719s 215ms/step - loss: 0.4537 - accuracy: 0.7827 - mse: 0.1484 - val_loss: 0.5900 - val_accuracy: 0.7135 - val_mse: 0.1955\n",
            "Epoch 5/5\n",
            "8000/8000 [==============================] - 1699s 212ms/step - loss: 0.4325 - accuracy: 0.7949 - mse: 0.1407 - val_loss: 0.6197 - val_accuracy: 0.7108 - val_mse: 0.2018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd274af4588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHdy1S0g1lXz",
        "colab_type": "text"
      },
      "source": [
        "RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcCJ1dhCEZgd",
        "colab_type": "code",
        "outputId": "4c8b790e-4c51-464f-819e-6f6e03fef405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Upgrading tensorflow\n",
        "# !pip uninstall tensorflow\n",
        "# !pip install tensorflow==2.0.0-beta1\n",
        "\n",
        "import tensorflow\n",
        "import theano\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqCb-L0aRqTr",
        "colab_type": "code",
        "outputId": "0b887975-fecc-40fc-d6e2-f37636bd48ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjPlC43zRPcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Google_Stock_Price_Train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CSwAgcFRPgi",
        "colab_type": "code",
        "outputId": "98b609d5-3fdd-4783-b586-7b3aaeba9f9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/3/2012</td>\n",
              "      <td>325.25</td>\n",
              "      <td>332.83</td>\n",
              "      <td>324.97</td>\n",
              "      <td>663.59</td>\n",
              "      <td>7,380,500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/4/2012</td>\n",
              "      <td>331.27</td>\n",
              "      <td>333.87</td>\n",
              "      <td>329.08</td>\n",
              "      <td>666.45</td>\n",
              "      <td>5,749,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/5/2012</td>\n",
              "      <td>329.83</td>\n",
              "      <td>330.75</td>\n",
              "      <td>326.89</td>\n",
              "      <td>657.21</td>\n",
              "      <td>6,590,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/6/2012</td>\n",
              "      <td>328.34</td>\n",
              "      <td>328.77</td>\n",
              "      <td>323.68</td>\n",
              "      <td>648.24</td>\n",
              "      <td>5,405,900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/9/2012</td>\n",
              "      <td>322.04</td>\n",
              "      <td>322.29</td>\n",
              "      <td>309.46</td>\n",
              "      <td>620.76</td>\n",
              "      <td>11,688,800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date    Open    High     Low   Close      Volume\n",
              "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
              "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
              "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
              "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
              "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WroZ11tBRPjH",
        "colab_type": "code",
        "outputId": "39229979-ff65-4697-fc56-b0bd1432d94c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "trainset = df_train.iloc[:,1:2].values\n",
        "trainset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHO5bP5JTnpu",
        "colab_type": "code",
        "outputId": "1d4ecfee-2fae-48d1-a207-3c7978b44bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler()\n",
        "\n",
        "train_sc = sc.fit_transform(trainset)\n",
        "train_sc.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAaYCTEvTnsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, 1258):\n",
        "    X_train.append(train_sc[i-60:i, 0])\n",
        "    y_train.append(train_sc[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME_coThaTn2u",
        "colab_type": "code",
        "outputId": "07ec53e8-38d8-4cb9-dc43-e348d067f6c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1198,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dOznNMlTnzR",
        "colab_type": "code",
        "outputId": "d5881a6c-1e98-4eda-fa67-177a053314c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1198, 60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91XZDsM3Tnw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshaping\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UX8TApVTnvH",
        "colab_type": "code",
        "outputId": "4b9caf59-3060-4071-c469-9527a1e93442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Initialising the RNN\n",
        "regressor = Sequential()\n",
        "\n",
        "# Adding the first LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding the output layer\n",
        "regressor.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the RNN\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Fitting the RNN to the Training set\n",
        "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 1198 samples\n",
            "Epoch 1/100\n",
            "1198/1198 [==============================] - 11s 9ms/sample - loss: 0.0398\n",
            "Epoch 2/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0061\n",
            "Epoch 3/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0051\n",
            "Epoch 4/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0054\n",
            "Epoch 5/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0050\n",
            "Epoch 6/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0049\n",
            "Epoch 7/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0058\n",
            "Epoch 8/100\n",
            "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0045\n",
            "Epoch 9/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0042\n",
            "Epoch 10/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0044\n",
            "Epoch 11/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0048\n",
            "Epoch 12/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0043\n",
            "Epoch 13/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0045\n",
            "Epoch 14/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0038\n",
            "Epoch 15/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0037\n",
            "Epoch 16/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0034\n",
            "Epoch 17/100\n",
            "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0038\n",
            "Epoch 18/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0033\n",
            "Epoch 19/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0039\n",
            "Epoch 20/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0035\n",
            "Epoch 21/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0030\n",
            "Epoch 22/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0030\n",
            "Epoch 23/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0033\n",
            "Epoch 24/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0031\n",
            "Epoch 25/100\n",
            "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0031\n",
            "Epoch 26/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0030\n",
            "Epoch 27/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0034\n",
            "Epoch 28/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0040\n",
            "Epoch 29/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0034\n",
            "Epoch 30/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0028\n",
            "Epoch 31/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0027\n",
            "Epoch 32/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0031\n",
            "Epoch 33/100\n",
            "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0029\n",
            "Epoch 34/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0028\n",
            "Epoch 35/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0029\n",
            "Epoch 36/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0030\n",
            "Epoch 37/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0030\n",
            "Epoch 38/100\n",
            "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0025\n",
            "Epoch 39/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0026\n",
            "Epoch 40/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0026\n",
            "Epoch 41/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0026\n",
            "Epoch 42/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0024\n",
            "Epoch 43/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0023\n",
            "Epoch 44/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0025\n",
            "Epoch 45/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0026\n",
            "Epoch 46/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0023\n",
            "Epoch 47/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0022\n",
            "Epoch 48/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0023\n",
            "Epoch 49/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0024\n",
            "Epoch 50/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0024\n",
            "Epoch 51/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0023\n",
            "Epoch 52/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0023\n",
            "Epoch 53/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
            "Epoch 54/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0027\n",
            "Epoch 55/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
            "Epoch 56/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0020\n",
            "Epoch 57/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
            "Epoch 58/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0020\n",
            "Epoch 59/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0019\n",
            "Epoch 60/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
            "Epoch 61/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
            "Epoch 62/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0022\n",
            "Epoch 63/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0018\n",
            "Epoch 64/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
            "Epoch 65/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0020\n",
            "Epoch 66/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0019\n",
            "Epoch 67/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0020\n",
            "Epoch 68/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
            "Epoch 69/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0017\n",
            "Epoch 70/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0019\n",
            "Epoch 71/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0018\n",
            "Epoch 72/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0021\n",
            "Epoch 73/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0017\n",
            "Epoch 74/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0018\n",
            "Epoch 75/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0018\n",
            "Epoch 76/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0017\n",
            "Epoch 77/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0017\n",
            "Epoch 78/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0015\n",
            "Epoch 79/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0017\n",
            "Epoch 80/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0016\n",
            "Epoch 81/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0018\n",
            "Epoch 82/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0015\n",
            "Epoch 83/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0016\n",
            "Epoch 84/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0016\n",
            "Epoch 85/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0015\n",
            "Epoch 86/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0017\n",
            "Epoch 87/100\n",
            "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0016\n",
            "Epoch 88/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0014\n",
            "Epoch 89/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0014\n",
            "Epoch 90/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0015\n",
            "Epoch 91/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0015\n",
            "Epoch 92/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0016\n",
            "Epoch 93/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0015\n",
            "Epoch 94/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0015\n",
            "Epoch 95/100\n",
            "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0013\n",
            "Epoch 96/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0014\n",
            "Epoch 97/100\n",
            "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0016\n",
            "Epoch 98/100\n",
            "1198/1198 [==============================] - 8s 7ms/sample - loss: 0.0013\n",
            "Epoch 99/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0013\n",
            "Epoch 100/100\n",
            "1198/1198 [==============================] - 8s 6ms/sample - loss: 0.0013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f19b9813128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc-nLJixTnnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 3 - Making the predictions and visualising the results\n",
        "\n",
        "# Getting the real stock price of 2017\n",
        "df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Google_Stock_Price_Test.csv')\n",
        "real_stock_price = df_test.iloc[:, 1:2].values\n",
        "\n",
        "# Getting the predicted stock price of 2017\n",
        "dataset_total = pd.concat((df_train['Open'], df_test['Open']), axis = 0)\n",
        "inputs = dataset_total[len(dataset_total) - len(df_test) - 60:].values # [1198:1298] ie 100 values\n",
        "inputs = inputs.reshape(-1,1)\n",
        "inputs = sc.transform(inputs)\n",
        "X_test = []\n",
        "for i in range(60, 80):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCtAS0hal4sL",
        "colab_type": "code",
        "outputId": "af7f5dcd-ed99-493d-8fef-ebb229f79315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(dataset_total)-len(df_test)-60  # 1278 - 20 - 60 = 1198"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aimdbPrnYaq_",
        "colab_type": "code",
        "outputId": "78ee5523-41a0-4386-d3d4-21d057538542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(df_train['Open']) # 1258"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1258"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bALuKiGbvUf",
        "colab_type": "code",
        "outputId": "329e57f2-3b59-4c58-937c-d173f8560bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(df_test['Open']) # 20"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5oUPju1RPfC",
        "colab_type": "code",
        "outputId": "c388441d-3f12-42ab-a82a-cc0c94ffcbb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Visualising the results\n",
        "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
        "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
        "plt.title('Google Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Google Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmJlZzknBzMxy/wfJ8XOHlrTxYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33pxd5c5fXBZ",
        "colab_type": "text"
      },
      "source": [
        "CNN CAR AND TRUCK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUbhZmCzsJob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzip the  dataset\n",
        "!unzip '/content/Data_Cars and Trucks.zip'\n",
        "#Splits the folders into training and testing\n",
        "!pip install split_folders tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yoG6gaNfWG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split Dataset folder into train and val folders\n",
        "import split_folders\n",
        "split_folders.ratio('/content/Datasets', output=\"data\", seed=1337, ratio=(.8, .2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-d-6KMwfWQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,3,3, input_shape = (64, 64, 3), activation='relu', kernel_initializer='uniform'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(32, 3,3, kernel_initializer='uniform', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(32, 3,3, kernel_initializer='uniform', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(32, 3,3, kernel_initializer='uniform', activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1rS0zthfWTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/data/train',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/data/val',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=629, # Number of images in train set\n",
        "    epochs=5,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=159) # Number of images in test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMarV4-MfWWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtaJTsC-fWZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEKsSfltfWb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXwP_LHKfWNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}